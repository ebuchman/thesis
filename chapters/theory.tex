\chapter{Theory}

This chapter introduces some theoretical formalisms for describing consensus networks.
First and foremost, we introduce a formal definition of trust on the basis of mutual information,
and show how the use of cryptography can increase the amount of trust in a system, 
enabling higher-level forms of communication.
Second, we formalize the consensus and atomic broadcast problems using process calculi 
and define a blockchain as a generic means for transforming consenus into atomic broadcast.
Third, we introduce Byzantine Failure Detectors for the detection of malicious processes,
and show how they can be used in a consensus protocol to achieve accountability.
Fourth, we consider probabilistic solutions to consensus, formalizing the common coin and proof-of-work approaches,
and show how a generalization of PoW in asynchronous conditions results in a protocol like Casper.
Finally, we describe how to formally introduce economics into the model, and discuss the resulting problem space.

\section{Trust and Information}

It is well known that \emph{trust}, defined as ...,
is a crucial element to maintaining productive socioeconomic systems \cite{trust}.
Intuitively, trust reduces uncertainty about the world, 
and enables higher-order forms of organization to flourish.

- communications channel, capacity as MI
- crypto primitives are axes for high entropy systems with high MI 'paths' for 'correct' processes

- crypto systems are stronger than purely info-theoretic ones \cite{ben1988completeness}



Suppose we have agents Alice and Bob, represented by random variables $A$ and $B$, 
operating in an uncertain environment, $X$.
Each agent mantains a representation of the world that defines a distribution over possible events 
in the universe, which for each agent consists of the other agent and the environment.
Let Alice's distribution be denoted $p_A(B, X) = p_A(B | X)p_A(X) $. 
The distribution has some entropy, $H[p_A]$. 
If Alice trusts Bob, we expect that the entropy, in particular that related to Bob, should decrease. 


We then define ``$A$ trusts $B$'' as an


Formally, we can define trust as a reduction in entropy 





\emph{Trust} as expected mutual information.
\emph{Correct-trust} as mutual information where you can see when it fails (crypto).
Show that correct-trust increases possible trust.

Digital signatures.
Merkle trees, erasure codes for broadcast.
Hash-chain links to simplify proposer logic.
Reduce complexity of network protocols by moving elements from data to authenticators.






\section{Consensus and Atomic Broadcast}
The problem has been pitched as consensus or atomic broadcast (ABC).
Consensus commits a value; ABC orders transactions.
Can show they are the same \cite{chandra1996unreliable}
We show they are the same with generalized process calculus forms of each and a bi-simualtion between them.
Atomic broadcast is the more natural form for real systems.

Note the pi calculus doesn't allow a strictly composable encoding of broadcast \cite{ene1999expressiveness},
but we don't need it, since in practice each node has a network stack/kernel that manages broadcasts.
Further, we really do want point-to-point, rather than broadcast,
because we want connections to be encrypted on a per-connection basis,
though group-encrypted broadcast primitives would be an interesting pursuit.

Reliable broadcast (RBC) is a broadcast primitive satisfying

\begin{itemize}
\item validity - if a correct process broadcasts m, it eventually delivers m
\item agreement - if a correct process delivers m, all correct processes eventually deliver m
\item integrity - m is only delivered once, and only if broadcast by its sender
\end{itemize}

We model RBC as a pi-calculus process, 
$rbc(\hat{r}, \hat{d}) = (\nu \hat{x}) \prod_i rb_i(r_i, d_i, \hat{x})$,
where $rbc_i$ is the instance of RBC running on node $i$, 
$\hat{r}$ are input channels, with one for each node, 
on which new requests from clients can be received, 
$d_i$ are $delivery$ channels, on which a node outputs RBC-delivered values,
and $\hat{x}$ are some shared variables.

We can state the properties in a temporal henessy-milner logic with fixed-point operators:
\begin{itemize}
\item validity - $ \forall m$, and correct $i$, $rbc |= [ r_i?(m) ] . \nu Z . ( d_i!(m)T \vee [*]Z) $
\item agreement - $ \forall m$, and correct $i$, $rbc |= [ d_i!(m) ] . \wedge_{j \neq i} ( \nu Z . (d_j!(m)T \vee [*]Z) $
\item integrity - $ \forall m$, and correct $i$, $rbc |= [ d_i!(m) ] . [ * ] . < d_i!(m) > ff $, and only if broadcast by its sender ...
\end{itemize}

Let us now model atomic broadcast ABC after RBC, as 
$abc(\hat{r}, \hat{d}) = (\nu \hat{x}) \prod_i abc_i(r_i, d_i, \hat{x})$,
with the same properties as $rbc$, but with the addition of \emph{total order},
\begin{itemize}
\item total order - if correct processes p and q deliver m and m', then p delivers m before m' iff q delivers m before m'
\end{itemize}


That is, ABC is identical to RBC, with the added constraint that reads off of any $d_i$ 
must return the same values in the same order.

We can model consensus similarly, as 
$cns(\hat{r}, \hat{d}) = (\nu \hat{x}) \prod_i cns_i(r_i, d_i, \hat{x})$,

with the following properties

\begin{itemize}
\item termination - every correct process eventually decides
\item integrity - every correct process decides at most once
\item agreement - if one correct process decides $v1$ and another decides $v2$, then $v1=v2$
\item validity - if a correct process decides $v$, at least one process proposed $v$
\end{itemize}

Note that the forms of consensus and ABC are identical (save some function names),
with the major difference in the properties relating to the fact that consenus
manages only one value, while atomic broadcast may handle many.

To show an equivalence between ABC and consensus,
we create a process context for each,
yielding $ C_{CNS}[ abc_i ] $ and $ C_{ABC}[ cns_i ] $ 
where we intend to show that 
$ C_{CNS}[ abc_i ] \sim cns_i $ and $ C_{ABC}[ cns_i ] \sim abc_i $ for
some weak bisimulation $\sim$.

Intuitevely, consensus can be derrived from ABC by deciding the first value fired on $d_i$,
while ABC can be derrived from consensus by running the consensus protocol multiple times,
once for each value, or batch of values, to be atomically broadcast.
Thus $ C_{CNS}[ ] $ is a context which restricts $d_i$, such that it is only read from once,
while $ C_{ABC}[ ] $ is a context which manages multiple instances of consensus, delivering on $d_i$ many times.


\section{Byzantine Failure Detectors}
Failure detectors (FDs), an abstraction of timeouts,
were introduced and used to solve consensus \cite{chandra1996unreliable}.
FDs enable processes to keep a list of other processes they suspect to have crashed.
Though unreliable, in that they may be suspicious of correct processes,
FDs can be constrained by abstract asymptotic properties ensuring that 
eventually, crashed processes are suspect, and correct processes are not.
Notably, the formalism of FDs enable refined investigation of consensus algorithms.

Here, we extend the model the Byzantine case, yielding Byzantine Failure Detectors,
and show how they can be used as building blocks for the construction of BFT algorithms.


Notes
- "correct" behaviour vs arbitrary behaviour
- nodes keep state of other nodes in order to know what is "allowed" and detect variation
- depending on the protocol, there may be a tradeoff between detection and asynchrony
	- non-byz may be suspected as byz cuz of asynchrony
	- conjecture: this only possible in non-strongly-consistent protocols
- tendermint has perfect byz detection since no tradeoff against asynchrony!
- what about pbft? need to review view change
- pi calc allows us to describe many of the BFDs implicitly by whether or not
we even listen for the message (eg. proposing when its not your turn)
- economics as a modulator for moving to next proposer





Byzantine Failure Detectors (BFDs) are a different breed.
While Byzantine traditionally means "arbitrary", 
it is in practice trivial to enforce simple rules which restrict
the set of messages which might affect the state.
Furthermore, Byzantine behaviour wherein a process does not send a message when it should have 
is indistinguishable from asynchrony.
Thus, BFDs must only be concerned with a particular class of Byzantine behaviour,
namely, that which is \emph{malicious}.
Unlike FDs, BFDs are not unreliable - they can not mistakenly suspect other processes
of being Byzantine, as triggering the BFD requires cryptographic proof.

There are two forms of malicious behaviour, which we call divergent-broadcast (DBC)
and unjustified-broadcast (UBC). In DBC, a process sends conflicting messages to peers.
Detecting DBC simply requires receiving the conflicting messages.
In UBC, a process sends a message which claims something about its internal state which is untrue.
To detect UBC requires the use of functions from the particular consensus protocol itself,
which must define a set of justification rules.
Either form of malicious behaviour is sufficient to violate safety in a non-Byzantine protocol.

We now define a BFD as satisfying the following property:

\begin{itemize}
\item{Eventually, every DBC and UBC is detected by at least one correct process}
\end{itemize}

In practice, using a BFD requires a correct process to keep a list of all messages it has delivered,
and to reliably broadcast those messages to all other correct processes.
Further, the BFD must be informed by the rules of the consensus protocol as to what constitutes a UBC.

Note that something which is a UBC in one protocol may not be in another.
We are interested in this boundary, particularly the weakest UBCs necessary for consensus.
Introduction of economics can weaken the UBCs necessary
	- eg PoW: mining an alternate chain doesn't get detected and punished, but economics yeilds an op cost
	- eg Casper: changing bets might incur small economic cost for larger reward of getting consensus sooner


Many BFT protocols are tolerant of Byzantine faults, but don't emphasize detection.
Thus, while a BFD is not necessary for Byzantine consensus, we show that, for some 
forms of the justification function, it is sufficient,
and that their use elucidates deeper structure in the BFT problem.






When no processes are malicious,
every message from a process can be trusted as an accurate reflection of that process' state.



FDs can be formalized with the pi-calculus, 
and resulting consensus protocols subject to a matrix analysis \cite{nestmann2003modeling}.
We'd like a similar analysis, with a more general notion of justification.
Most previous byz algos dont focus on detection, just tolerance.

Further, we'd like to show that justifications can be removed from the real-time
protocol and moved to a post-failure recovery mode protocol, under some weak network assumptions,
without compromising accountability.

Start by defining messages as consisting of three parts: indices, authenticators, data.
Indices are things like height number, round number, message type number, etc.
Authenticators are signatures and hashes.
Cant do BFT without authenticators (tho wtf about some of those papers ...)
Byzantine msgs are those with the same indices and authenticators, but different data.
Note this assumes deterministic authenticators, and implies that detection requires gossip.
We also want byzantine msgs to be those that are "unjustified".
Introduce "justification" rules which map $(AUTH, DATA)$ to $\{True, False\}$.

Also note how moving data/indices into auth using hashes can simplify protocols
(eg. the way linking to the previous block avoids subtle leader crash/recover scenarios).

\section{Probabilistic Solutions}
Consensus can be solved with FDs or with randomness.
Common coin gives probabilistic liveness, where randomness is over what value sent.
Bitcoin gives probabilistic safety, where randomness is over when value sent.
There seems to be a duality here, common coin being like $\wedge$ and bitcoin like $\vee$.
How to reflect in stochastic-pi calc logic.

Bitcoin makes synchrony assumption that network latency is much less than block time,
allowing it to give strong (economic/probabilistic) serializability guarantees.
GHOST weakens the synchrony assumption by using additional network information to inform fork choice.
Is the asynchronous generalization of GHOST something like casper?
How does the move from PoW to PoS complement that from synchrony to asynchrony?

\section{Economics}
Suppose the consensus system is probabilistic, ala some stochastic process calculus.
Economics are a way to parameterize the Comm rates of the calculus,
such that the param values may change, subject to some constraints 
(eg. the avg value over time is constant, etc.).
The point of the system is to be valuable,
and have this value be contributed back to the processes as wealth.
Economics makes the system reflexive, in the sense that,
given finite critical resources and a driving energy source,
the system must increase its efficiency (ie. innovate, build wealth, etc),
to maintain liveness during growth.
Integration with food systems, be an organism, etc.

Note economics can also act as a weak/parametrized form of synchrony!

\section{Residence Times}
Drawing inspiration from ecology and biophysics, 
where its been suggested that residence time of energy in a non-equilibrium system is a 
measure of its organizational complexity.

Consider a network of processes in such a light.
Energy input is receipt of a msg. 
Causes a tree of execution. 
Residence time is (eg.) time until all branches of the tree either communicate with other trees or halt.
Here, txs are the inputs (ie. they should pay fees!).
Another energy input is eg. POW - can be measured as a packet of energy arriving as a new block.
Without inflation, packets arrive and are immediately released as heat, minus what is paid in fees,
which hang around as a balance and prolong the residence time.
The inflation increases the residence time, but is clearly unsustainable - distribution mechanisms are important tho!
Alternatively, in POS, packets come in as security deposits, which sit around for a long time ...
